{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Image Self-Supervised Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# NOTHING TODO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from pathlib import Path\n",
    "import paths\n",
    "from datasets import VOCDataset\n",
    "voc_path = Path(paths.CV_PATH_VOC)\n",
    "dataset = VOCDataset(voc_path, voc_path / \"ImageSets\" / \"Segmentation\" / \"val.txt\",\n",
    "                     load_captions=True)\n",
    "# dataset.classe\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine dataset\n",
    "# NOTHING TODO\n",
    "\n",
    "query = 'cat' # cat boat\n",
    "query_ids = [] \n",
    "labels = []\n",
    "for i in range(len(dataset)):\n",
    "    data = dataset[i]\n",
    "    if query in data[\"caption\"]: \n",
    "        query_ids.append(i)\n",
    "        print(i)\n",
    "        display(data[\"image\"])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize filtered samples\n",
    "# NOTHING TODO \n",
    "\n",
    "query_ids = [78, 288, 133, 415] # cat \n",
    "query_ids = [27, 898, 2, 29, 535] # boat\n",
    "for i in query_ids:\n",
    "    data = dataset[i]\n",
    "    display(data[\"image\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Self-Supervised Feature Extractor\n",
    "# NOTHING TODO\n",
    "\n",
    "from models.segmentation import vit_small\n",
    "\n",
    "# DINOv2\n",
    "use_dinov2 = False\n",
    "\n",
    "#if use_dinov2:\n",
    "model_selfsup = torch.hub.load(\n",
    "                repo_or_dir=\"facebookresearch/dinov2\", # \"facebookresearch/dinov2\"  \"./ckpt/dino_deitsmall16_pretrain\"\n",
    "                model=\"dinov2_vits14\", # dinov2_vits14 dino_deitsmall16_pretrain\n",
    "                pretrained=True,\n",
    "            )\n",
    "patch_size = 14\n",
    "\n",
    "# else:\n",
    "#     model_selfsup = vit_small()\n",
    "#     ckpt_path = Path(paths.CV_PATH_CKPT) / \"dino_deitsmall16_pretrain.pth\"\n",
    "#     model_selfsup.load_state_dict(torch.load(ckpt_path))\n",
    "#     print(f\"Loaded encoder weights from {ckpt_path}\")\n",
    "#     patch_size = 16\n",
    "\n",
    "_ = model_selfsup.eval()\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), # imagenet defaults\n",
    "      ])\n",
    "\n",
    "def label_transform(target):\n",
    "    return torch.as_tensor(np.array(target), dtype=torch.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define methods\n",
    "# NOTHING TODO\n",
    "\n",
    "def forward(frame: dict):\n",
    "\n",
    "    img: Image = frame[\"image\"]\n",
    "    label: Image = frame[\"label\"]\n",
    "    \n",
    "    x = img_transform(img)\n",
    "    _img_size = list(x.shape[1:3])\n",
    "    _feat_map_size = [int(s // patch_size) for s in _img_size]\n",
    "    _img_crop_size = [s * patch_size for s in _feat_map_size]\n",
    "\n",
    "    x = x[:, :_img_crop_size[0], :_img_crop_size[1]]\n",
    "    x_dict = model_selfsup.forward_features(x[None,])\n",
    "    x_feat_map = x_dict[\"x_norm_patchtokens\"][0].reshape(*(_feat_map_size + [-1,])).permute(2, 0, 1)\n",
    "    x_feat_cls = x_dict[\"x_norm_clstoken\"][0]\n",
    "\n",
    "    y = label_transform(label)\n",
    "    #dataset.classes\n",
    "    # background: 0:\n",
    "    # boat: 4\n",
    "    # cat: 8\n",
    "    mask = (y > 0) * (y < 255) #  * (y > 0.) * (y < 1.)  # label provides pixel-wise annotation between for classes in range (0.,1.) \n",
    "    mask_crop = mask[:_img_crop_size[0], :_img_crop_size[1]]\n",
    "    mask_transform = transforms.Resize(size=_feat_map_size, interpolation=transforms.InterpolationMode.NEAREST)\n",
    "    mask_feat_map = mask_transform(mask_crop[None,])[0]\n",
    "\n",
    "    frame['feat_map'] = x_feat_map\n",
    "    frame['mask_feat_map'] = mask_feat_map\n",
    "\n",
    "    frame['feat_map_np'] = frame['feat_map'].detach().numpy()\n",
    "    frame['feats_np'] = frame['feat_map'].flatten(1).permute(1, 0).detach().numpy()\n",
    "    frame['feat_patch_size'] = patch_size\n",
    "    \n",
    "    return frame\n",
    "\n",
    "def get_frame_center_crop(frame):\n",
    "    frame_crop = {}\n",
    "    W, H = frame[\"image\"].size\n",
    "    # (left, upper, right, lower) cropping coordiantes\n",
    "    left = W//4\n",
    "    upper = H//4\n",
    "    right = 3*(W//4)\n",
    "    lower = 3*(H//4)\n",
    "    frame_crop[\"image_orig\"] = frame[\"image\"].copy()\n",
    "    # flips: FLIP_LEFT_RIGHT, FLIP_TOP_BOTTOM, ROTATE_90 \n",
    "    frame_crop[\"image\"] = frame[\"image\"].transpose(Image.FLIP_TOP_BOTTOM).crop((left, upper, right, lower))\n",
    "    frame_crop[\"label\"] = frame[\"label\"].transpose(Image.FLIP_TOP_BOTTOM).crop((left, upper, right, lower))\n",
    "    frame_crop['crop'] = True\n",
    "    \n",
    "    return frame_crop # this dict contains cropped version of original data\n",
    "\n",
    "def idx_to_xy(idx, map2d, scale=None):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            idx(np.array): AxBxC\n",
    "            map2d(Union[np.array, torch.Tensor]): ...xHxW\n",
    "            scale (int)\n",
    "        Returns:\n",
    "            xy(np.array): AxBxCx2\n",
    "    \"\"\"\n",
    "    W = map2d.shape[-1]\n",
    "    if idx is None:\n",
    "        idx = np.arange(map2d.shape[-1] * map2d.shape[-2]) # H * W\n",
    "    y = (idx // W)\n",
    "    x = (idx % W)\n",
    "    if scale is not None:\n",
    "        y = (y+0.5) * scale\n",
    "        x = (x+0.5) * scale\n",
    "    xy = np.stack([x, y], axis=-1)\n",
    "    return xy\n",
    "    \n",
    "def display_tensor(t: torch.Tensor):\n",
    "    _transform = transforms.ToPILImage()\n",
    "    if t.dtype == torch.bool:\n",
    "        t = t.clone() * 1.\n",
    "    display(_transform(t))\n",
    "\n",
    "def display_matches(match_A_to_B, frame_A, frame_B, match_A_to_B_scores=None, top_k=10):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        match_A_to_B (np.array): N,\n",
    "        match_A_to_B_scores (np.array): N,\n",
    "        match_A_to_B_scores_quantile (float)\n",
    "        frame_A\n",
    "        frame_B\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.patches import ConnectionPatch\n",
    "    import numpy as np\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax_A = fig.add_subplot(121)\n",
    "    ax_B = fig.add_subplot(122)\n",
    "\n",
    "    ax_A.imshow(frame_A[\"image\"])\n",
    "    ax_B.imshow(frame_B[\"image\"])\n",
    "\n",
    "    if match_A_to_B_scores is not None:\n",
    "        match_ids_A = np.argsort(match_A_to_B_scores)[::-1]\n",
    "    else:\n",
    "        match_ids_A = np.random.permutation(len(match_A_to_B_scores))\n",
    "        \n",
    "    if top_k > 0:\n",
    "        match_ids_A = match_ids_A[:top_k]\n",
    "        \n",
    "    for id_A in match_ids_A:\n",
    "        if match_A_to_B_scores[id_A] == -np.inf:\n",
    "            continue\n",
    "            \n",
    "        id_B = match_A_to_B[id_A]\n",
    "\n",
    "        # Upsample\n",
    "        xy_A = idx_to_xy(id_A, frame_A[\"feat_map\"], scale=frame_A['feat_patch_size'])\n",
    "        xy_B = idx_to_xy(id_B, frame_B[\"feat_map\"], scale=frame_B['feat_patch_size'])\n",
    "\n",
    "        con = ConnectionPatch(xyA=xy_A, xyB=xy_B, coordsA=\"data\", coordsB=\"data\",\n",
    "                              axesA=ax_A, axesB=ax_B, color=np.random.rand(3,))\n",
    "        ax_B.add_artist(con)\n",
    "    plt.show()\n",
    "\n",
    "def display_matches_1_to_K(match_A_to_Bs, frame_A, frame_Bs, match_A_to_Bs_scores=None, top_k=10):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        match_A_to_Bs (np.array): NxB,\n",
    "        match_A_to_Bs_scores (np.array): N,\n",
    "        match_A_to_Bs_scores_quantile (float)\n",
    "        frame_A\n",
    "        frame_Bs (list)\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.patches import ConnectionPatch\n",
    "    import numpy as np\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    B = len(frame_Bs)\n",
    "    ax_A = fig.add_subplot(B* 100 + B*10 + 1)\n",
    "    ax_Bs = []\n",
    "    for b in range(B):\n",
    "        ax_Bs.append(fig.add_subplot(B* 100 + 2*10 + 2 + b * 2))\n",
    "\n",
    "    ax_A.imshow(frame_A[\"image\"])\n",
    "    for b in range(B):\n",
    "        ax_Bs[b].imshow(frame_Bs[b][\"image\"])\n",
    "\n",
    "    if match_A_to_Bs_scores is not None:\n",
    "        match_ids_A = np.argsort(match_A_to_Bs_scores)[::-1]\n",
    "    else:\n",
    "        match_ids_A = np.random.permutation(len(match_A_to_Bs_scores))\n",
    "        \n",
    "    if top_k > 0:\n",
    "        match_ids_A = match_ids_A[:top_k]\n",
    "\n",
    "    colors = np.random.rand(len(match_ids_A), 3,)\n",
    "    for b in range(B):\n",
    "        match_A_to_B = match_A_to_Bs[b]\n",
    "        match_A_to_B_scores = match_A_to_Bs_scores\n",
    "        frame_B = frame_Bs[b]\n",
    "        ax_B = ax_Bs[b]\n",
    "        for i, id_A in enumerate(match_ids_A):\n",
    "            if match_A_to_B_scores[id_A] == -np.inf:\n",
    "                continue\n",
    "            id_B = match_A_to_B[id_A]\n",
    "\n",
    "            # Upsample\n",
    "            xy_A = idx_to_xy(id_A, frame_A[\"feat_map\"], scale=frame_A['feat_patch_size'])\n",
    "            xy_B = idx_to_xy(id_B, frame_B[\"feat_map\"], scale=frame_B['feat_patch_size'])\n",
    "    \n",
    "            con = ConnectionPatch(xyA=xy_A, xyB=xy_B, coordsA=\"data\", coordsB=\"data\",\n",
    "                                  axesA=ax_A, axesB=ax_B, color=colors[i])\n",
    "            ax_B.add_artist(con)\n",
    "    plt.show()\n",
    "\n",
    "def display_matches_crop_error(match_As_to_Bs, match_As_to_Bs_scores, frame_As, frame_Bs, top_k=5):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        match_As_to_Bs (Union[list, np.array]): list or N,\n",
    "        match_As_to_Bs_scores (Union[list, np.array]): list or N,\n",
    "        frame_As (Union[list, dict])\n",
    "        frame_Bs (Union[list, dict])\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    if not isinstance(match_As_to_Bs, list):\n",
    "        match_As_to_Bs = [match_As_to_Bs]\n",
    "        match_As_to_Bs_scores = [match_As_to_Bs_scores]\n",
    "        frame_As = [frame_As]\n",
    "        frame_Bs = [frame_Bs]\n",
    "\n",
    "    match_errors_total = []\n",
    "    K = len(match_As_to_Bs)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    for k in range(K):\n",
    "        match_A_to_B = match_As_to_Bs[k]\n",
    "        match_A_to_B_scores = match_As_to_Bs_scores[k]\n",
    "        frame_A = frame_As[k]\n",
    "        frame_B = frame_Bs[k]\n",
    "            \n",
    "        # sort from best to worst ( highest to lowest score)\n",
    "        match_A_to_B_sorted_ids = np.argsort(match_A_to_B_scores)[::-1]\n",
    "        \n",
    "        xy_A = idx_to_xy(None, map2d=frame_A['feat_map'], scale=frame_A['feat_patch_size'])\n",
    "        xy_B = idx_to_xy(match_A_to_B, map2d=frame_B['feat_map'], scale=frame_B['feat_patch_size'])\n",
    "        \n",
    "        if frame_A.get(\"crop\", False):\n",
    "            W, H = frame_A[\"image_orig\"].size\n",
    "            xy_A[:, 0] += W // 4\n",
    "            xy_A[:, 1] += H // 4\n",
    "            #xy_A[:, 0] = W - xy_A[:, 0] # flip left-to-right            \n",
    "            xy_A[:, 1] = H - xy_A[:, 1] # flip top-to-bottom\n",
    "        \n",
    "        if frame_B.get(\"crop\", False):        \n",
    "            W, H = frame_B[\"image_orig\"].size\n",
    "            xy_B[:, 0] += W // 4\n",
    "            xy_B[:, 1] += H // 4\n",
    "            #xy_B[:, 0] = W - xy_B[:, 0] # flip left-to-right\n",
    "            xy_B[:, 1] = H - xy_B[:, 1] # flip top-to-bottom\n",
    "\n",
    "        top_matches_ids = match_A_to_B_sorted_ids[:top_k]\n",
    "        match_errors = np.linalg.norm(xy_A - xy_B, axis=-1)\n",
    "\n",
    "        match_errors_total.append(match_errors[top_matches_ids])\n",
    "        #plt.plot(match_A_to_B_scores[match_A_to_B_sorted_ids], label='score')\n",
    "        \n",
    "        from scipy.interpolate import make_interp_spline, BSpline, make_lsq_spline\n",
    "        \n",
    "        # 300 represents number of points to make between x.min and x.max\n",
    "        match_errors_sorted = match_errors[match_A_to_B_sorted_ids]\n",
    "        x = np.arange(len(match_errors_sorted))\n",
    "        \n",
    "        xnew = np.linspace(x.min(), x.max(), 10)  \n",
    "        spl = make_interp_spline(x, match_errors_sorted, k=3)  #,=3 type: BSpline\n",
    "        match_errors_sorted_smooth = spl(xnew)\n",
    "        \n",
    "        plt.plot(xnew, match_errors_sorted_smooth, label=f'crop error [{k}]')\n",
    "        plt.legend(loc=\"upper left\")\n",
    "        plt.xlabel('rank')\n",
    "        plt.ylabel('match errors')\n",
    "    \n",
    "    plt.show()    \n",
    "    match_errors_total = np.concatenate(match_errors_total)\n",
    "    print(f\"err. mean (top: {top_k})\", np.mean(match_errors_total))\n",
    "    print(f\"err. median (top: {top_k})\", np.median(match_errors_total))\n",
    "\n",
    "def get_matches_frames_A_to_B(frame_A, frame_B, get_matches_feats_A_to_B, mask=True, pca_k=-1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        frame_A(dict)\n",
    "        frame_B(dict)\n",
    "        get_matches_feats_A_to_B (method): Takes feature maps (FxH1xW1) and (FxH1xW1) as input and returns matches and scores. \n",
    "        mask (bool)\n",
    "        pca_k (int)\n",
    "    Returns:\n",
    "        match_A_to_B (np.array): N1,\n",
    "        match_A_to_B_scores (np.array): N1,\n",
    "    \"\"\"\n",
    "    frame_A = forward(frame_A)\n",
    "    frame_B = forward(frame_B)\n",
    "\n",
    "    feats_A = frame_A['feat_map_np'] # F x H1 x W1\n",
    "    feats_B = frame_B['feat_map_np'] # F x H2 x W2\n",
    "\n",
    "    if pca_k > 0:\n",
    "        feats = np.concatenate([frame_A['feats_np'], frame_B['feats_np']], axis=0)\n",
    "        pca = PCA(n_components=pca_k)\n",
    "        pca.fit(feats)\n",
    "        #print(feats_A.shape, feats_B.shape)\n",
    "        feats_A = pca.transform(frame_A['feats_np']).reshape(feats_A.shape[1], feats_A.shape[2], pca_k).transpose((2, 0, 1))\n",
    "        feats_B = pca.transform(frame_B['feats_np']).reshape(feats_B.shape[1], feats_B.shape[2], pca_k).transpose((2, 0, 1))\n",
    "        #print(feats_A.shape, feats_B.shape)\n",
    "    \n",
    "    match_A_to_B, match_A_to_B_scores = get_matches_feats_A_to_B(feats_A, feats_B)\n",
    "    # match_A_to_B, match_A_to_B_scores = get_matches_feats_A_to_B(frame_A, frame_B, get_matches_feats_A_to_B, mask, pca_k)\n",
    "    \n",
    "    xy_A = idx_to_xy(idx=None, map2d=frame_A['feat_map'])\n",
    "    xy_B = idx_to_xy(idx=match_A_to_B, map2d=frame_B['feat_map'])\n",
    "\n",
    "    if mask:\n",
    "        # mask A\n",
    "        match_A_to_B_scores[~frame_A['mask_feat_map'][xy_A[:, 1], xy_A[:, 0]]] = -np.inf\n",
    "        # mask B\n",
    "        match_A_to_B_scores[~frame_B['mask_feat_map'][xy_B[:, 1], xy_B[:, 0]]] = -np.inf\n",
    "\n",
    "    return match_A_to_B, match_A_to_B_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Nearest Neighbor Features with Negative Feature Space Distance as Score \n",
    "# TODO: Complete method get_matches_feats_A_to_B_nn. This method takes as input two feature maps.\n",
    "#       It returns the Nearest Neighbors for each feature of feature map A to the features of feature map B.\n",
    "#       Additionally, it returns the negative distance for each match in feature space as score. (1 Points)\n",
    "\n",
    "\n",
    "def get_matches_feats_A_to_B_nn(feats_A, feats_B):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        feats_A(np.array): FxH1xW1\n",
    "        feats_B(np.array): FxH2xW2\n",
    "    Returns:\n",
    "        match_A_to_B (np.array): H1*W1,\n",
    "        match_A_to_B_scores (np.array): H1*W1,\n",
    "    \"\"\"\n",
    "    \n",
    "    # START TODO\n",
    "    \n",
    "    # Reshaping of feat_A and feat_B into 2D array\n",
    "    feats_A_flat = feats_A.reshape(feats_A.shape[0], -1).T\n",
    "    feats_B_flat = feats_B.reshape(feats_B.shape[0], -1).T\n",
    "\n",
    "    # finding nearest neighbor for each feature in 'feat_A' within feat space 'feat_B'\n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(feats_B_flat)\n",
    "    # indices = indices of NNs in 'feat_B_flat'\n",
    "    # distances = dist between 'feat_A_flat' and 'feat_B_flat'\n",
    "    distances, indices = nbrs.kneighbors(feats_A_flat, return_distance=True) # returns distances and indices of NNs.\n",
    "\n",
    "    # contains indices of NNs in 'feat_B_flat' for each feature in 'feat_A_flat'\n",
    "    match_A_to_B = indices.flatten()\n",
    "    # -ve dist between each feature in 'flat_A_flat' and NN in 'feat_B_flat'\n",
    "    match_A_to_B_scores = -distances.flatten()\n",
    "    \n",
    "    # END TODO\n",
    "    \n",
    "    return match_A_to_B, match_A_to_B_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize Nearest Neighbors for Debugging\n",
    "# NOTHING TODO\n",
    "\n",
    "ids_cat = [78, 288, 133, 415] # cat \n",
    "ids_boat = [27, 898, 2, 29, 535] # boat\n",
    "\n",
    "frame_ref = dataset[288].copy() \n",
    "frame_src = dataset[78].copy()\n",
    "\n",
    "#frame_src = get_frame_center_crop(frame_ref)\n",
    "#frame_ref = get_frame_center_crop(frame_src)\n",
    "\n",
    "match_ref_to_src, match_ref_to_src_scores= get_matches_frames_A_to_B(\n",
    "    frame_A = frame_ref,\n",
    "    frame_B = frame_src,\n",
    "    get_matches_feats_A_to_B=get_matches_feats_A_to_B_nn,\n",
    "    mask=True,\n",
    "    pca_k=-1)\n",
    "\n",
    "display_matches(match_A_to_B=match_ref_to_src, match_A_to_B_scores=match_ref_to_src_scores, \n",
    "                frame_A=frame_ref, frame_B=frame_src, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2. Visualize Nearest Neighbors and Calculate Crop Error with Feature Distance Ranking\n",
    "# TODO: Add the cropped-matches-error plot into your report using the cats images with image ids [78, 288, 133, 415]. \n",
    "#       Also add the output for mean and median error for the top 10 matches.\n",
    "#       Describe the plot with your own words. (2 Points)\n",
    "#       Note: To make a screenshot of the whole plot, right-click on the cell's output and click \"Disable Scrolling for Outputs\".\n",
    "\n",
    "ids_cat = [78, 288, 133, 415] # cat \n",
    "\n",
    "match_refs_to_srcs = []\n",
    "match_refs_to_srcs_scores = []\n",
    "frame_refs = []\n",
    "frame_srcs = []\n",
    "\n",
    "for id_cat in ids_cat:\n",
    "    frame_ref = dataset[id_cat].copy() \n",
    "    frame_src = dataset[id_cat].copy()\n",
    "\n",
    "    frame_src = get_frame_center_crop(frame_ref)\n",
    "    \n",
    "    match_ref_to_src, match_ref_to_src_scores= get_matches_frames_A_to_B(\n",
    "        frame_A = frame_ref,\n",
    "        frame_B = frame_src,\n",
    "        get_matches_feats_A_to_B=get_matches_feats_A_to_B_nn,\n",
    "        mask=False,\n",
    "        pca_k=-1)\n",
    "\n",
    "    display_matches(match_A_to_B=match_ref_to_src, match_A_to_B_scores=match_ref_to_src_scores, \n",
    "                    frame_A=frame_ref, frame_B=frame_src, top_k=10)\n",
    "\n",
    "    match_refs_to_srcs.append(match_ref_to_src)\n",
    "    match_refs_to_srcs_scores.append(match_ref_to_src_scores)\n",
    "    frame_refs.append(frame_ref)\n",
    "    frame_srcs.append(frame_src)\n",
    "\n",
    "display_matches_crop_error(match_As_to_Bs=match_refs_to_srcs, match_As_to_Bs_scores=match_refs_to_srcs_scores, \n",
    "                           frame_As=frame_refs, frame_Bs=frame_srcs, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Nearest Neighbor Features with Negative Cycle Distance as Score \n",
    "# TODO: Complete method get_matches_feats_A_to_B_nn_with_score_cycle_dist. This method takes as input two feature maps.\n",
    "#       It returns the Nearest Neighbors for each feature of feature map A to the features of feature map B.\n",
    "#       Additionally, it returns the negative cycle distance for each pair in pixel space as score. (1 Points)\n",
    "\n",
    "def get_matches_feats_A_to_B_nn_with_score_cycle_dist(feats_A, feats_B):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        feats_A(np.array): FxH1xW1\n",
    "        feats_B(np.array): FxH2xW2\n",
    "    Returns:\n",
    "        match_A_to_B (np.array): H1*W1,\n",
    "        match_A_to_B_scores (np.array): H1*W1,\n",
    "    \"\"\"\n",
    "    \n",
    "    # START TODO\n",
    "    # F, H1, W1 = feats_A.shape\n",
    "    # H2, W2 = feats_B.shape[1], feats_B.shape[2]\n",
    "    \n",
    "    # Reshape feature maps to (N, F) where N is the number of patches (H*W)\n",
    "    # feats_A_reshaped = feats_A.reshape(F, H1 * W1).T  # Shape: (H1*W1, F)\n",
    "    # feats_B_reshaped = feats_B.reshape(F, H2 * W2).T  # Shape: (H2*W2, F)\n",
    "    \n",
    "    # 'feats_A' and 'feats_B' reshaped into 2D array\n",
    "    feats_A = feats_A.reshape(feats_A.shape[0], -1)\n",
    "    feats_B = feats_B.reshape(feats_B.shape[0], -1)\n",
    "\n",
    "    # stores NN index \n",
    "    match_A_to_B = []\n",
    "    # stores -ve cycle distance\n",
    "    match_A_to_B_scores = []\n",
    "\n",
    "    # computing Euclidean distance between feature vector and its NN in 'feats_A'\n",
    "    for i in range(feats_A.shape[1]):  # iterate over each cell/pixel of A\n",
    "        feat_A = feats_A[:, i]  # Shape: (F,)\n",
    "        \n",
    "        distances_A_to_B = np.linalg.norm(feats_B - feat_A[:, np.newaxis], axis=0)  #  Find nearest neighbors of feature vectors of A in B\n",
    "        min_index_B = np.argmin(distances_A_to_B)\n",
    "        \n",
    "        feat_B = feats_B[:, min_index_B]  # Shape: (F,)\n",
    "        distances_B_to_A = np.linalg.norm(feats_A - feat_B[:, np.newaxis], axis=0)  # Find its Nearest Neighbors in A\n",
    "        min_index_A = np.argmin(distances_B_to_A)\n",
    "        \n",
    "        cycle_distance = np.linalg.norm(feat_A - feats_A[:, min_index_A])  # Calculate Euclidean Distance between min_index_A and A       \n",
    "        match_A_to_B.append(min_index_B)\n",
    "        match_A_to_B_scores.append(-cycle_distance)\n",
    "    \n",
    "   \n",
    "    match_A_to_B = np.array(match_A_to_B)\n",
    "    match_A_to_B_scores = np.array(match_A_to_B_scores)\n",
    "\n",
    "    # END TODO\n",
    "    \n",
    "    return match_A_to_B, match_A_to_B_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Nearest Neighbors for Debugging\n",
    "# NOTHING TODO\n",
    "\n",
    "ids_cat = [78, 288, 133, 415] # cat \n",
    "\n",
    "frame_ref = dataset[288].copy() \n",
    "frame_src = dataset[78].copy()\n",
    "\n",
    "#frame_src = get_frame_center_crop(frame_ref)\n",
    "#frame_ref = get_frame_center_crop(frame_src)\n",
    "\n",
    "match_ref_to_src, match_ref_to_src_scores= get_matches_frames_A_to_B(\n",
    "    frame_A = frame_ref,\n",
    "    frame_B = frame_src,\n",
    "    get_matches_feats_A_to_B=get_matches_feats_A_to_B_nn_with_score_cycle_dist,\n",
    "    mask=False,\n",
    "    pca_k=-1)\n",
    "\n",
    "# print(frame_A.shape)\n",
    "# print(frame_B.shape)\n",
    "\n",
    "display_matches(match_A_to_B=match_ref_to_src, match_A_to_B_scores=match_ref_to_src_scores, \n",
    "                frame_A=frame_ref, frame_B=frame_src, top_k=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4. Visualize Nearest Neighbors and Calculate Crop Error with Cycle Distance Ranking\n",
    "# TODO: Add the cropped-matches-error plot into your report using the cats images with image ids [78, 288, 133, 415]. \n",
    "#       Also add the output for mean and median error for the top 10 matches.\n",
    "#       How does the cycle distance score performs against the feature distance score? (2 Points)\n",
    "#       Note: To make a screenshot of the whole plot, right-click on the cell's output and click \"Disable Scrolling for Outputs\".\n",
    "\n",
    "ids_cat = [78, 288, 133, 415] # cat \n",
    "\n",
    "match_refs_to_srcs = []\n",
    "match_refs_to_srcs_scores = []\n",
    "frame_refs = []\n",
    "frame_srcs = []\n",
    "for id_cat in ids_cat:\n",
    "    frame_ref = dataset[id_cat].copy() \n",
    "    frame_src = dataset[id_cat].copy()\n",
    "\n",
    "    frame_src = get_frame_center_crop(frame_ref)\n",
    "    \n",
    "    match_ref_to_src, match_ref_to_src_scores= get_matches_frames_A_to_B(\n",
    "        frame_A = frame_ref,\n",
    "        frame_B = frame_src,\n",
    "        get_matches_feats_A_to_B=get_matches_feats_A_to_B_nn_with_score_cycle_dist,\n",
    "        mask=False,\n",
    "        pca_k=-1)\n",
    "\n",
    "    display_matches(match_A_to_B=match_ref_to_src, match_A_to_B_scores=match_ref_to_src_scores, \n",
    "                    frame_A=frame_ref, frame_B=frame_src, top_k=10)\n",
    "\n",
    "    match_refs_to_srcs.append(match_ref_to_src)\n",
    "    match_refs_to_srcs_scores.append(match_ref_to_src_scores)\n",
    "    frame_refs.append(frame_ref)\n",
    "    frame_srcs.append(frame_src)\n",
    "\n",
    "display_matches_crop_error(match_As_to_Bs=match_refs_to_srcs, match_As_to_Bs_scores=match_refs_to_srcs_scores, \n",
    "                           frame_As=frame_refs, frame_Bs=frame_srcs, top_k=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5 Complete Nearest Neighbors Matches for 1-to-Many Frames \n",
    "# TODO: Complete method get_matches_frames_A_to_Bs. This method takes as input one reference frame (A) and multiple source frames (Bs).\n",
    "#       It returns the Nearest Neighbors Matches for each feature of feature map A to the features of each feature map B (of Bs).\n",
    "#       Additionally, it returns the score for each matched feature of feature map A. \n",
    "#       This score is averaged over all scores for a single feature matched with multiple source feature maps (Bs). \n",
    "#       If pca_k > 0, map the features to a pca_k-dimensional subspace using PCA. (2 Points)\n",
    "\n",
    "def get_matches_frames_A_to_Bs(frame_A, frame_Bs, get_matches_feats_A_to_B, mask=True, pca_k=-1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        frame_A(dict)\n",
    "        frame_Bs(list): B frames\n",
    "        get_matches_feats_A_to_B (method): Takes feature maps (FxH1xW1) and (FxH1xW1) as input and returns matches and scores.\n",
    "        mask (bool)\n",
    "        pca_k (int)\n",
    "    Returns:\n",
    "        match_A_to_Bs (np.array): N1xB\n",
    "        match_A_to_Bs_scores (np.array): N1,\n",
    "    \"\"\"\n",
    "\n",
    "    # START TODO\n",
    "    \n",
    "    match_A_to_Bs = []\n",
    "    match_A_to_Bs_scores = []\n",
    "    \n",
    "    # Compute features for frame A\n",
    "    frame_A = forward(frame_A)\n",
    "    feats_A = frame_A['feat_map_np']\n",
    "\n",
    "    print(\"Shape of A before PCA\", feats_A.shape)\n",
    "    \n",
    "    # If PCA dimensionality reduction is requested\n",
    "    if pca_k > 0:\n",
    "        F, H1, W1 = feats_A.shape\n",
    "        feats_A = feats_A.reshape(F, H1 * W1).T  # Shape (H1*W1, F)\n",
    "        \n",
    "        pca = PCA(n_components=pca_k)\n",
    "        feats_A = pca.fit_transform(feats_A)\n",
    "        feats_A = feats_A.T.reshape(pca_k, H1, W1)  # Shape (pca_k, H1, W1)\n",
    "\n",
    "    print(\"Shape of A after PCA\", feats_A.shape)\n",
    "    \n",
    "    # Compute matches for each frame B\n",
    "    for frame_B in frame_Bs:\n",
    "        # Compute features for frame B\n",
    "        frame_B = forward(frame_B)\n",
    "        feats_B = frame_B['feat_map_np']\n",
    "        \n",
    "        # If PCA dimensionality reduction is requested\n",
    "        print(\"Shape of B before PCA\", feats_B.shape)\n",
    "        if pca_k > 0:\n",
    "            F, H2, W2 = feats_B.shape\n",
    "            feats_B = feats_B.reshape(F, H2 * W2).T  # Shape (H2*W2, F)\n",
    "            feats_B = pca.transform(feats_B)\n",
    "            feats_B = feats_B.T.reshape(pca_k, H2, W2)\n",
    "\n",
    "        print(\"Shape of B after PCA\", feats_B.shape)\n",
    "        \n",
    "        # Compute matches and scores for frame A to frame B\n",
    "        match_A_to_B, match_A_to_B_scores = get_matches_feats_A_to_B(feats_A, feats_B)\n",
    "        \n",
    "        match_A_to_Bs.append(match_A_to_B)\n",
    "        match_A_to_Bs_scores.append(match_A_to_B_scores)\n",
    "    \n",
    "    # Convert scores to numpy arrays\n",
    "    match_A_to_Bs_scores = np.array(match_A_to_Bs_scores)\n",
    "    \n",
    "    # If mask is True, filter out invalid matches\n",
    "    if mask:\n",
    "        mask_A = frame_A['mask_feat_map'].flatten()\n",
    "        mask_A_to_Bs = []\n",
    "        for match_A_to_B in match_A_to_Bs:\n",
    "            mask_B = frame_Bs[match_B]['mask_feat_map'].flatten()\n",
    "            mask_A_to_Bs.append(mask_B[match_A_to_B])\n",
    "        \n",
    "        mask_A_to_Bs = np.array(mask_A_to_Bs)\n",
    "        match_A_to_Bs_scores[~mask_A] = -np.inf\n",
    "        match_A_to_Bs_scores[~mask_A_to_Bs] = -np.inf\n",
    "    \n",
    "    # Calculate average scores for each feature matched with multiple source feature maps (Bs)\n",
    "    match_A_to_Bs_scores_avg = np.mean(match_A_to_Bs_scores, axis=0)\n",
    "    \n",
    "    return np.array(match_A_to_Bs), match_A_to_Bs_scores_avg    \n",
    "\n",
    "    # END TODO\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.6. Visualize Nearest Neighbors Matches for 1-to-Many Frames \n",
    "# TODO: Add the nearest neighbor visualization for the reference cat image (id 78) with the source images (ids 288, 133, 415) to your report.\n",
    "#       Show four different methods. \n",
    "#       A) get_matches_feats_A_to_B_nn without PCA. \n",
    "#       B) get_matches_feats_A_to_B_nn with PCA (10 components). \n",
    "#       C) get_matches_feats_A_to_B_nn_with_score_cycle_dist without PCA\n",
    "#       D) get_matches_feats_A_to_B_nn_with_score_cycle_dist with PCA (10 components). \n",
    "#       What is the advantage of using PCA?\n",
    "#       What is the advantage of using the negative cycle distance as score? (2 Points)\n",
    "\n",
    "ids_cat = [78, 288, 133, 415] # cat \n",
    "\n",
    "query_ids = ids_cat\n",
    "\n",
    "ref_id = query_ids[0]\n",
    "src_ids = query_ids[1:]\n",
    "\n",
    "frame_ref = dataset[ref_id].copy()\n",
    "frame_srcs = []\n",
    "for src_id in src_ids:\n",
    "    frame_srcs.append(dataset[src_id].copy())\n",
    "\n",
    "print ('-------------------------------A) get_matches_feats_A_to_B_nn without PCA-----------------------------------------')\n",
    "\n",
    "match_ref_to_srcs, match_ref_to_srcs_scores = get_matches_frames_A_to_Bs(\n",
    "    frame_ref, frame_srcs, mask=False, pca_k=-1,\n",
    "    get_matches_feats_A_to_B=get_matches_feats_A_to_B_nn) \n",
    "\n",
    "\n",
    "print(match_ref_to_srcs_scores.shape)\n",
    "display_matches_1_to_K(match_A_to_Bs=match_ref_to_srcs, match_A_to_Bs_scores=match_ref_to_srcs_scores, \n",
    "                       frame_A=frame_ref, frame_Bs=frame_srcs, top_k=5)\n",
    "\n",
    "print ('-------------------------------B) get_matches_feats_A_to_B_nn with PCA (10 components)-----------------------------------------')\n",
    "\n",
    "match_ref_to_srcs, match_ref_to_srcs_scores = get_matches_frames_A_to_Bs(\n",
    "    frame_ref, frame_srcs, mask=False, pca_k=10,\n",
    "    get_matches_feats_A_to_B=get_matches_feats_A_to_B_nn) #_with_score_cycle_dist\n",
    "\n",
    "\n",
    "print(match_ref_to_srcs_scores.shape)\n",
    "display_matches_1_to_K(match_A_to_Bs=match_ref_to_srcs, match_A_to_Bs_scores=match_ref_to_srcs_scores, \n",
    "                       frame_A=frame_ref, frame_Bs=frame_srcs, top_k=5)\n",
    "\n",
    "print ('-------------------------------C) get_matches_feats_A_to_B_nn_with_score_cycle_dist without PCA-----------------------------------------')\n",
    "\n",
    "match_ref_to_srcs, match_ref_to_srcs_scores = get_matches_frames_A_to_Bs(\n",
    "    frame_ref, frame_srcs, mask=False, pca_k=-1,\n",
    "    get_matches_feats_A_to_B=get_matches_feats_A_to_B_nn_with_score_cycle_dist) #_with_score_cycle_dist\n",
    "\n",
    "\n",
    "print(match_ref_to_srcs_scores.shape)\n",
    "display_matches_1_to_K(match_A_to_Bs=match_ref_to_srcs, match_A_to_Bs_scores=match_ref_to_srcs_scores, \n",
    "                       frame_A=frame_ref, frame_Bs=frame_srcs, top_k=5)\n",
    "\n",
    "print ('-----------------------------D) get_matches_feats_A_to_B_nn_with_score_cycle_dist with PCA (10 components)-------------------------------------------')\n",
    "\n",
    "match_ref_to_srcs, match_ref_to_srcs_scores = get_matches_frames_A_to_Bs(\n",
    "    frame_ref, frame_srcs, mask=False, pca_k=10,\n",
    "    get_matches_feats_A_to_B=get_matches_feats_A_to_B_nn_with_score_cycle_dist) \n",
    "\n",
    "\n",
    "print(match_ref_to_srcs_scores.shape)\n",
    "display_matches_1_to_K(match_A_to_Bs=match_ref_to_srcs, match_A_to_Bs_scores=match_ref_to_srcs_scores, \n",
    "                       frame_A=frame_ref, frame_Bs=frame_srcs, top_k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
